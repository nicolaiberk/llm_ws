{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolaiberk/llm_ws/blob/main/notebooks/01b_text_reps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27372a8",
      "metadata": {
        "id": "b27372a8"
      },
      "source": [
        "# Tabular data & text representation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e9a2e1",
      "metadata": {
        "id": "e8e9a2e1"
      },
      "source": [
        "In this notebook, we'll learn how to work with tabular data using the `pandas` library. We will also explore some basic text preprocessing and representation techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1dd2d94",
      "metadata": {
        "id": "b1dd2d94"
      },
      "source": [
        "## Intro to `pandas`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b214ff4",
      "metadata": {
        "id": "1b214ff4"
      },
      "source": [
        "Before we delve into the use of the `pandas` library, we first need to understand how to load libraries. Libraries are collections of functions and other objects, provided by the python community for us to use (you might be familiar with the R equivalent of packages). To import them into our session, we simply use the `import` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7848e5e4",
      "metadata": {
        "id": "7848e5e4"
      },
      "outputs": [],
      "source": [
        "import pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1001b3",
      "metadata": {
        "id": "1f1001b3"
      },
      "source": [
        "Then we can use it's functions and objects. For pandas, arguably the most relevant class is the dataframe. This object stores data in a two-dimensional matrix with rows and columns. We can supply a dictionary to the function to define a basic table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da689ec",
      "metadata": {
        "id": "5da689ec"
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame(\n",
        "{\"a\" : [4, 5, 6],\n",
        "\"b\" : [7, 8, 9],\n",
        "\"c\" : [10, 11, 12]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd07be5d",
      "metadata": {
        "id": "dd07be5d"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304d445c",
      "metadata": {
        "id": "304d445c"
      },
      "source": [
        "To select a column, we can either use `.` or use brackets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75728064",
      "metadata": {
        "id": "75728064"
      },
      "outputs": [],
      "source": [
        "df.c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d31c26",
      "metadata": {
        "id": "f9d31c26"
      },
      "outputs": [],
      "source": [
        "df['c']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c2c508",
      "metadata": {
        "id": "07c2c508"
      },
      "source": [
        "Similarly, we can select rows by subsetting with brackets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe52e31b",
      "metadata": {
        "id": "fe52e31b"
      },
      "outputs": [],
      "source": [
        "df[df.a > 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982426fc",
      "metadata": {
        "id": "982426fc"
      },
      "source": [
        "To select specific rows, you can also use `df.index`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54dda9ec",
      "metadata": {
        "id": "54dda9ec"
      },
      "outputs": [],
      "source": [
        "df[df.index == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e74df01",
      "metadata": {
        "id": "7e74df01"
      },
      "source": [
        "To select rows and columns at the same time, you can subset sequentially:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fce2b02",
      "metadata": {
        "id": "6fce2b02"
      },
      "outputs": [],
      "source": [
        "df.c[df.a > 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "067cdc10",
      "metadata": {
        "id": "067cdc10"
      },
      "source": [
        "*Exercise: select the first observation of the b row.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f69062",
      "metadata": {
        "id": "22f69062"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "37b2c2a5",
      "metadata": {
        "id": "37b2c2a5"
      },
      "source": [
        "To assign values, you can use the bracket logic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f643513",
      "metadata": {
        "id": "4f643513"
      },
      "outputs": [],
      "source": [
        "df['a'] = 1\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa005d1",
      "metadata": {
        "id": "6fa005d1"
      },
      "outputs": [],
      "source": [
        "df[df.index == 0] = 2\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df102dd5",
      "metadata": {
        "id": "df102dd5"
      },
      "source": [
        "You can create new columns the same way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1618ae",
      "metadata": {
        "id": "7b1618ae"
      },
      "outputs": [],
      "source": [
        "df['d'] = [5,25,125]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc890ff",
      "metadata": {
        "id": "5cc890ff"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b704d90",
      "metadata": {
        "id": "1b704d90"
      },
      "source": [
        "To assign a specific value, you shoud use `.loc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb2ffb4",
      "metadata": {
        "id": "6cb2ffb4"
      },
      "outputs": [],
      "source": [
        "df.loc[df.index == 2, 'c'] = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977d6a49",
      "metadata": {
        "id": "977d6a49"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f26204a",
      "metadata": {
        "id": "1f26204a"
      },
      "source": [
        "More useful is the calculation with entire dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db203da",
      "metadata": {
        "id": "0db203da"
      },
      "outputs": [],
      "source": [
        "df/2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f980783",
      "metadata": {
        "id": "1f980783"
      },
      "source": [
        "*Exercise: create a new column 'e', which is the difference between the d and the c columns.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393e7b44",
      "metadata": {
        "id": "393e7b44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1700b37e",
      "metadata": {
        "id": "1700b37e"
      },
      "source": [
        "Lastly, you can store a dataframe to a local file, e.g. a csv-file. You can then also load it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49e0c4c",
      "metadata": {
        "id": "d49e0c4c"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"test_file.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19eac238",
      "metadata": {
        "id": "19eac238"
      },
      "outputs": [],
      "source": [
        "df_load = pandas.read_csv(\"test_file.csv\")\n",
        "df_load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26fc4e9e",
      "metadata": {
        "id": "26fc4e9e"
      },
      "source": [
        "More: [pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfca59b3",
      "metadata": {
        "id": "bfca59b3"
      },
      "source": [
        "## BoW"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b4aaf7",
      "metadata": {
        "id": "79b4aaf7"
      },
      "source": [
        "Now that we understand how to work with dataframes, we can create a document-term matrix (DTM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad292b0",
      "metadata": {
        "id": "aad292b0"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"This is the first document.\",\n",
        "    \"This is the second document.\",\n",
        "    \"This is the third document.\",\n",
        "    \"A completely completely unrelated text.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ceeb63",
      "metadata": {
        "id": "36ceeb63"
      },
      "source": [
        "First, we need to create a vocabulary of unique terms (the columns of our DTM):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1744199b",
      "metadata": {
        "id": "1744199b"
      },
      "outputs": [],
      "source": [
        "def vocab_generator(documents):\n",
        "    vocab = []\n",
        "    for doc in documents:\n",
        "        tokens = doc.split()\n",
        "        for token in tokens:\n",
        "            if token not in vocab:\n",
        "                vocab.append(token)\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33c1a123",
      "metadata": {
        "id": "33c1a123"
      },
      "source": [
        "*Exercise: look at each line in the function above: what is happening here?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6ba5c4",
      "metadata": {
        "id": "5a6ba5c4"
      },
      "outputs": [],
      "source": [
        "vocab_generator(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fa7c837",
      "metadata": {
        "id": "4fa7c837"
      },
      "source": [
        "This looks ok, but it probably makes sense to remove the punctuation and lowercase all tokens.\n",
        "\n",
        "*Exercise: create a function to remove punctuation and lowercase all tokens. Apply it to the documents, creating a new object with the processed documents called `processed_docs`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f6021b",
      "metadata": {
        "id": "01f6021b"
      },
      "outputs": [],
      "source": [
        "## your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77e92bf5",
      "metadata": {
        "id": "77e92bf5"
      },
      "source": [
        "We might also remove some stopwords when creating the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d2e2f5",
      "metadata": {
        "id": "b3d2e2f5"
      },
      "outputs": [],
      "source": [
        "def vocab_generator(documents, stop_words = [\"this\", \"is\", \"the\", \"a\"]):\n",
        "    vocab = []\n",
        "    for doc in documents:\n",
        "        tokens = doc.split()\n",
        "        for token in tokens:\n",
        "            if token not in vocab and token not in stop_words:\n",
        "                vocab.append(token)\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5ca6f7",
      "metadata": {
        "id": "af5ca6f7"
      },
      "outputs": [],
      "source": [
        "vocab = vocab_generator(processed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca50f08",
      "metadata": {
        "id": "bca50f08"
      },
      "source": [
        "Let's create a document term matrix! Let's start by creating one column per token in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fc01c4",
      "metadata": {
        "id": "b7fc01c4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dfm = pd.DataFrame([[0] * len(vocab)] * 4, columns=vocab)\n",
        "dfm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4711fb54",
      "metadata": {
        "id": "4711fb54"
      },
      "source": [
        "Note that we `import pandas as pd` here. Libraries can be renamed at import, and `pd` is the customary way to refer to this frequently used package."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad67983c",
      "metadata": {
        "id": "ad67983c"
      },
      "source": [
        "*Exercise: count the number of occurences of each term in each document and assign them to the DTM.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a406e4",
      "metadata": {
        "id": "f3a406e4"
      },
      "outputs": [],
      "source": [
        "## your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10cf7e1",
      "metadata": {
        "id": "a10cf7e1"
      },
      "source": [
        "## Processing text with `nltk`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb8756e",
      "metadata": {
        "id": "6eb8756e"
      },
      "source": [
        "A particularly useful library for basic operations with texts is the NLTK library (short for natural language toolkit). We can use it to stem or lemmatize some texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72bb7341",
      "metadata": {
        "id": "72bb7341"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# Initialize stemmer for English\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "# Test words with different morphological patterns\n",
        "test_words = [\n",
        "    'quick', 'quickly',\n",
        "    'university', 'universities',\n",
        "    'running', 'runs', 'ran'\n",
        "]\n",
        "\n",
        "for word in test_words:\n",
        "    stem = stemmer.stem(word)\n",
        "    print(stem)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58a1790",
      "metadata": {
        "id": "b58a1790"
      },
      "source": [
        "The package also contains a lemmatizer. To use it, we first need to download the necessary resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbc595f",
      "metadata": {
        "id": "edbc595f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b6c56a",
      "metadata": {
        "id": "14b6c56a"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer as wnl\n",
        "\n",
        "lemmatizer = wnl()\n",
        "\n",
        "for word in test_words:\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(lemma)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696bd905",
      "metadata": {
        "id": "696bd905"
      },
      "source": [
        "Which way the lemmatizer defines the lemma might depend on whether it recognizes a given word as a verb or a noun. This behavior will be more useful when used alongside a parts-of-speech tagger identifying whether a given term is a verb, noun, adjective, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c99fd1",
      "metadata": {
        "id": "63c99fd1"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "lemma = lemmatizer.lemmatize(\"ran\", wordnet.VERB)\n",
        "lemma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "927ea55b",
      "metadata": {
        "id": "927ea55b"
      },
      "source": [
        "*Exercise: Create your own word list and explore the differences between the two approaches further.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}