{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9a8a5f",
   "metadata": {},
   "source": [
    "# Transformers: Fine-tune your own BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d217fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (0.4.5)\n",
      "Requirement already satisfied: transformers in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69356d21",
   "metadata": {},
   "source": [
    "In this notebook, we will\n",
    "\n",
    "1) look at more functions from the ðŸ¤— `transformers` library\n",
    "2) learn how to work with ðŸ¤— `datasets`\n",
    "3) fine-tune a pre-trained BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774609ed",
   "metadata": {},
   "source": [
    "## What happens in `pipeline()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f9107",
   "metadata": {},
   "source": [
    "*This section is based on [Chapter 2](https://huggingface.co/learn/llm-course/chapter2/2) of the ðŸ¤— LLM Course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029cd45",
   "metadata": {},
   "source": [
    "You are already familiar with the `pipeline()` method from our preceding notebook. Here is an example to jog your memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aac581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9055778980255127},\n",
       " {'label': 'NEGATIVE', 'score': 0.9966409206390381}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"My research is going to be whole different ballgame using LLMs!\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e971b",
   "metadata": {},
   "source": [
    "Alright, so this little function takes text inputs and transforms them into label predictions. But since transformers cannot simply be fit on the raw texts, several things have to happen in the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d7e00",
   "metadata": {},
   "source": [
    "![Visualization from Chapter 2 of teh Huggingface Course](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045cfc4",
   "metadata": {},
   "source": [
    "You already know from our last session how to load tokenizers of specific models and tokenize input texts using `AutoTokenizer()`. Lets's repeat this briefly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6c2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\" # this is the default model for sentiment-analysis\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b95143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2026,  2470,  2003,  2183,  2000,  2022,  2878,  2367,  3608,\n",
      "         16650,  2478,  2222,  5244,   999,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"My research is going to be whole different ballgame using LLMs!\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6135312",
   "metadata": {},
   "source": [
    "*Can you explain what the padding and truncation parameters do here? What would the data look like if you would not specify them?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409afbe",
   "metadata": {},
   "source": [
    "Great. So we've already covered the first step! Let's look at how we could load a specific model and generate output embeddings of each text using our token IDs. We start by loading the model from the hub using `AutoModel()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b7fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e6a83",
   "metadata": {},
   "source": [
    "This architecture contains only the base Transformer module: given some inputs, it returns the output embeddings or *hidden states* of the model, which might then be fed into a classification head downstream. We can simply use the assigned object to run the forward pass and return the model embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48cabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc56b5",
   "metadata": {},
   "source": [
    "*Interpret these dimensions. What does each number describe?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d2b08",
   "metadata": {},
   "source": [
    "Now we need to transform these representations into useful classifications. As you heard already earlier today, models 'translate' embeddings into classifications using a **classification head**. Classification heads exist for many different tasks, e.g. question answering or token classification. We are interested in classifying our entire sequences. To do so, we load the model with a classification head for sequence classification using `AutoModelForSequenceClassification` instead of simply `AutoModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f48d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e08a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2da26",
   "metadata": {},
   "source": [
    "Instead of outputting the embeddings, this model contains a classification head which transforms the original, high-dimensional representation into a vector containing two values (one for each label). The values we get as output from our model donâ€™t necessarily make sense by themselves - they are so-called logits. We can transform them to values bounded between 0 and 1 using the `softmax` function you already saw earlier today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "993aa18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0940, 0.9060],\n",
      "        [0.9990, 0.0010]], grad_fn=<RoundBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions.round(decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52c686",
   "metadata": {},
   "source": [
    "To see which label corresponds to which prediction, you can check the model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7243f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3d5cd",
   "metadata": {},
   "source": [
    "## Working with ðŸ¤— `datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c99bc",
   "metadata": {},
   "source": [
    "Before we get started with training our own models, we need to understand how to provide useful inputs to our models. Huggingface provides a library called `datasets` to make our life a little easier. \n",
    "\n",
    "The most basic function in the datasets library is probably `load_dataset`. Using this function, we can load an annotated dataset of synthetically generated phone calls, annotated for whether a given conversation is a scam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"BothBosu/scam-dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f3e4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue', 'type', 'label'],\n",
       "        num_rows: 1280\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue', 'type', 'label'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b681c",
   "metadata": {},
   "source": [
    "As you can see, we get a dictionary (specifically, a `DatasetDict`) containing two parts of this dataset: a train set (referred to as a 'split) in the datasets lingo; and a test set. You can directly dowload either by specifying the split you are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb53d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"BothBosu/scam-dialogue\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cee319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialogue', 'type', 'label'],\n",
       "    num_rows: 1280\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07631c",
   "metadata": {},
   "source": [
    "We have three features: dialogue (containing the text of the conversation), the type of the conversation (which we will ignore here), and the label, that is the outcome of interest - whether the conversation was a scam call (1) or not (0). *You can check the [dataset card](https://huggingface.co/datasets/BothBosu/scam-dialogue) for more information.*\n",
    "\n",
    "You can inspect observations in the data simply by subsetting to the row of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ddc54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue': \"caller: Hello, is this John? receiver: Yes, it is. Who's calling? caller: My name is Officer Johnson from the Social Security Administration. How are you today? receiver: I'm fine, thank you. What can I do for you? caller: We've been trying to reach you about a very important matter. Your social security number has been compromised and we need to take immediate action to protect your identity. receiver: Oh no, what happened? caller: We've received reports of suspicious activity on your account and we need to verify some information to ensure your benefits aren't interrupted. receiver: Okay, what do you need to know? caller: Can you please confirm your social security number for me? receiver: Wait, I'm not comfortable giving that out over the phone. Is this really the Social Security Administration? caller: Ma'am, I assure you this is a legitimate call. We're trying to help you. If you don't cooperate, we'll have to suspend your benefits. receiver: I don't think so. I'm going to hang up and call the SSA myself to verify this. caller: Ma'am, don't hang up! You need to take care of this now or you'll be sorry!\",\n",
       " 'type': 'ssn',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8421a1",
   "metadata": {},
   "source": [
    "Another neat function is `train_test_split`: it divides the dataset into a train and a test set. We can use it here to subdivide our trainset into a validation and a training set. It is useful to set a seed for these operations, in order to make the process reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28ca07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_set = dataset['train'].train_test_split(test_size=0.1, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a3da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = train_val_set['train']\n",
    "dataset['validation'] = train_val_set['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2b5020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue', 'type', 'label'],\n",
       "        num_rows: 1152\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue', 'type', 'label'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue', 'type', 'label'],\n",
       "        num_rows: 128\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e61e0",
   "metadata": {},
   "source": [
    "Let's prepare the dataset by tokenizing the conversations. The datasets library offers a neat function called `map` to simply and quickly apply any transformation to our data. We start by loading the tokenizer of a pre-trained bert model and defining the function we want to apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d941fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode(examples):\n",
    "    return tokenizer(examples[\"dialogue\"], truncation=True, padding=\"max_length\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f814b26",
   "metadata": {},
   "source": [
    "We can then use `map` to encode each dataset in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26830692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1152/1152 [00:00<00:00, 3570.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [00:00<00:00, 4640.44 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 4693.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1152\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 128\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(encode, batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce7449",
   "metadata": {},
   "source": [
    "As you can see, we have added three columns to our dataset, containing the tokenizer output for each conversation. Note that the logic of map allows you to apply any transformation you want - you simply need to change the supplied function.\n",
    "\n",
    "Our model will expect a variable called 'labels' as outcome. So let's rename our variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848ad923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1152\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue', 'type', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 128\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962ef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93954d5b",
   "metadata": {},
   "source": [
    "Lastly, we select the columns of interest using `select_columns`. \n",
    "\n",
    "*For a full overview of pre-processing functions, check out the [datasets documentation](https://huggingface.co/docs/datasets/en/process).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b1908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select_columns([\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f0e08",
   "metadata": {},
   "source": [
    "*If you want to learn more about ðŸ¤— `datasets` you can check out the [`datasets` tutorial](https://huggingface.co/docs/datasets/en/quickstart) and the [chapter on `datasets` in the ðŸ¤— LLM course](https://huggingface.co/learn/llm-course/chapter5/1).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bd4d3",
   "metadata": {},
   "source": [
    "### Using your own data as a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bdf8df",
   "metadata": {},
   "source": [
    "datasets also offers helpful functions to load your own data. There are [many functions](https://huggingface.co/docs/datasets/en/loading) to do this, including loading directly from disk. However, especially if you need to prepare the dataset beforehand, it is usually simplest to work with `pandas` and then transform this dataframe to a datasets dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3b2a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "tmp_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ee7f1",
   "metadata": {},
   "source": [
    "## Fine-tuning a Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e22c21",
   "metadata": {},
   "source": [
    "Now you should be prepared to understand how to fine-tune your own model. We start by loading a model with the appropriate classification head and defining the number of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415f302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643f685",
   "metadata": {},
   "source": [
    "Huggingface offers the `Trainer` function to make training as simple as possible for us. All we need to do is to define some training arguments, supply the training and (optionally) validation data. We can specify many different hyperparameters in the training arguments, but possibly the most important one is the number of epochs - that is, full runs through the training data - you want the model to train. We also specify a validation strategy (once after every epoch) to assess how well our model predicts the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ab381d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test-trainer\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"epoch\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a45d3",
   "metadata": {},
   "source": [
    "We should also specify an evaluation metric to understand how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7716601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def acc_prec_rec_f1(predictions, references):\n",
    "    cm = pd.crosstab(predictions, references)\n",
    "    accuracy = np.diag(cm).sum() / cm.sum().sum()\n",
    "\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return acc_prec_rec_f1(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c59b9",
   "metadata": {},
   "source": [
    "Quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "801580aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [0,1,0,0,1]\n",
    "references =  [0,1,0,1,1]\n",
    "\n",
    "acc_prec_rec_f1(predictions, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ee9265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46828f2",
   "metadata": {},
   "source": [
    "You then train the model simply by running `trainer.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d6c72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/144 04:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=144, training_loss=0.034307145410113864, metrics={'train_runtime': 265.7918, 'train_samples_per_second': 4.334, 'train_steps_per_second': 0.542, 'total_flos': 303103935774720.0, 'train_loss': 0.034307145410113864, 'epoch': 1.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb970e",
   "metadata": {},
   "source": [
    "*What is happening during `trainer.train()`?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873bdfa1",
   "metadata": {},
   "source": [
    "Best to save the trained model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "059c35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_first_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f420b",
   "metadata": {},
   "source": [
    "You can generate predictions of the trained model using `model.predict()` now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc39f4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niberk/Dropbox (Personal)/Teaching/LLM_WS/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd6efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.586289 ,  5.2830496], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.predictions[0] # again, we get logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d078b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform logits to labels\n",
    "pred_labels = np.argmax(preds.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e259acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd30ab8",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model on our testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc024470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluate\n",
    "acc_prec_rec_f1(pred_labels, dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bbbabc",
   "metadata": {},
   "source": [
    "*Why would it be necessary or useful to use a separate testset here?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19dc99b",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08eeb8e",
   "metadata": {},
   "source": [
    "TIme to train your own classifier! Look for data of interest, start a new notebook and fine-tune a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea21d9",
   "metadata": {},
   "source": [
    "1. Start by identifying a reasonably sized dataset (max 100k rows) to use for sequence classification from the [transformers hub](https://huggingface.co/datasets?size_categories=or:%28size_categories:n%3C1K,size_categories:1K%3Cn%3C10K,size_categories:10K%3Cn%3C100K%29&sort=downloads). Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab4e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9107514",
   "metadata": {},
   "source": [
    "2. Preprocess the data appropriately. Split the data into train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007031de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "745b5926",
   "metadata": {},
   "source": [
    "3. Load a 'bert-base-uncased' model and train the model for at least one epoch. Explicitly define some other hyperparameters if you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeeb261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f05dbcb",
   "metadata": {},
   "source": [
    "4. Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fd4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
