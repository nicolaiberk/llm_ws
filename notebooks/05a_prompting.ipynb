{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd82ebca",
   "metadata": {},
   "source": [
    "# Annotation with Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457798d",
   "metadata": {},
   "source": [
    "## Generating text with generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c07f3",
   "metadata": {},
   "source": [
    "### Simple Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f84446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M-Instruct\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a63f1",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bde39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-360M-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-360M-Instruct\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c50f5",
   "metadata": {},
   "source": [
    "### Zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad546d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8459dd43",
   "metadata": {},
   "source": [
    "### Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6eb633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e73037",
   "metadata": {},
   "source": [
    "### Dynamic Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6379f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b752e701",
   "metadata": {},
   "source": [
    "### BONUS: Setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464ac08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a338354",
   "metadata": {},
   "source": [
    "## Controlling model output with `pydantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what we want to extract\n",
    "class Sentiment(BaseModel):\n",
    "    \"\"\"Simple sentiment analysis\"\"\"\n",
    "    sentiment: str = Field(description=\"Is this POSITIVE, NEGATIVE, or NEUTRAL?\")\n",
    "    confidence: float = Field(description=\"How confident are you? (0.0 to 1.0)\")\n",
    "\n",
    "# Test texts to analyze\n",
    "test_texts = [\n",
    "    \"I absolutely love this new policy! It will help so many families.\",\n",
    "    \"This decision is terrible and will hurt our community.\",\n",
    "    \"The committee met yesterday to discuss the budget proposal.\"\n",
    "]\n",
    "\n",
    "print(\"Analyzing sentiments:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for text in test_texts:\n",
    "    # Ask AI to analyze sentiment\n",
    "    response = chat(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Classify sentiment as POSITIVE, NEGATIVE, or NEUTRAL.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        model='qwen3:1.7b',\n",
    "        format=Sentiment.model_json_schema(),  # Use our structure\n",
    "    )\n",
    "\n",
    "    # Get the result\n",
    "    result = Sentiment.model_validate_json(response.message.content)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nText: '{text}'\")\n",
    "    print(f\"‚Üí Sentiment: {result.sentiment}\")\n",
    "    print(f\"‚Üí Confidence: {result.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81bba09",
   "metadata": {},
   "source": [
    "## Training Encoders with Synthetic Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80479c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ab856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Workshop: LLM Inference, Text Similarity, and Model Training\n",
    "# A hands-on introduction to modern NLP techniques with Hugging Face\n",
    "\n",
    "\"\"\"\n",
    "Workshop Outline:\n",
    "1. LLM Inference with Zero-shot and Few-shot Prompting\n",
    "2. Text Similarity using Transformer Embeddings\n",
    "3. Dynamic Few-shot Prompting\n",
    "4. Training BERT on Synthetic LLM Labels\n",
    "\n",
    "Prerequisites: Basic Python knowledge, familiarity with transformers concept\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Install required packages (run in terminal or uncomment below)\n",
    "# !pip install transformers torch sentence-transformers datasets scikit-learn\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoModel,\n",
    "    AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datasets import Dataset\n",
    "import random\n",
    "\n",
    "print(\"Setup complete! üöÄ\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: LLM INFERENCE WITH ZERO-SHOT AND FEW-SHOT PROMPTING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 1: LLM INFERENCE - ZERO-SHOT AND FEW-SHOT PROMPTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load a smaller language model for demonstration\n",
    "model_name = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_text(prompt, max_length=100, temperature=0.7):\n",
    "    \"\"\"Generate text using the loaded model\"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ZERO-SHOT PROMPTING EXAMPLE\n",
    "print(\"\\nüìù Zero-shot Prompting Example:\")\n",
    "zero_shot_prompt = \"Classify the sentiment of this text as positive, negative, or neutral: 'I love this product!' Answer:\"\n",
    "\n",
    "result = generate_text(zero_shot_prompt, max_length=50)\n",
    "print(f\"Prompt: {zero_shot_prompt}\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# STUDENT INTERACTION 1\n",
    "print(\"\\nü§î STUDENT EXERCISE 1:\")\n",
    "print(\"Try creating your own zero-shot prompt for a different task (e.g., topic classification, question answering)\")\n",
    "print(\"Modify the 'your_prompt' variable below and run the cell!\")\n",
    "\n",
    "# TODO: Students fill this in\n",
    "your_prompt = \"Classify this email as spam or not spam: 'Get rich quick! Click here now!' Answer:\"\n",
    "your_result = generate_text(your_prompt, max_length=50)\n",
    "print(f\"Your result: {your_result}\")\n",
    "\n",
    "# FEW-SHOT PROMPTING EXAMPLE\n",
    "print(\"\\nüìù Few-shot Prompting Example:\")\n",
    "few_shot_prompt = \"\"\"\n",
    "Classify sentiment as positive, negative, or neutral:\n",
    "\n",
    "Text: \"This movie was amazing!\"\n",
    "Sentiment: positive\n",
    "\n",
    "Text: \"I hated every minute of it.\"\n",
    "Sentiment: negative\n",
    "\n",
    "Text: \"It was okay, nothing special.\"\n",
    "Sentiment: neutral\n",
    "\n",
    "Text: \"Best purchase ever!\"\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "result = generate_text(few_shot_prompt, max_length=60)\n",
    "print(f\"Few-shot result: {result}\")\n",
    "\n",
    "# STUDENT INTERACTION 2\n",
    "print(\"\\nü§î STUDENT EXERCISE 2:\")\n",
    "print(\"Compare zero-shot vs few-shot results. Which performs better? Why?\")\n",
    "print(\"Try adding more examples to the few-shot prompt and observe the difference.\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: TEXT SIMILARITY USING TRANSFORMER EMBEDDINGS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 2: TEXT SIMILARITY WITH TRANSFORMER EMBEDDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load sentence transformer model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    \"\"\"Calculate cosine similarity between two texts\"\"\"\n",
    "    embeddings = sentence_model.encode([text1, text2])\n",
    "    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Example texts for similarity comparison\n",
    "texts = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A feline rested on the rug.\",\n",
    "    \"Dogs are great pets.\",\n",
    "    \"I love pizza and pasta.\",\n",
    "    \"Italian food is delicious.\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìä Text Similarity Matrix:\")\n",
    "print(\"Comparing different text pairs:\")\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        similarity = calculate_similarity(texts[i], texts[j])\n",
    "        print(f\"'{texts[i][:30]}...' vs '{texts[j][:30]}...': {similarity:.3f}\")\n",
    "\n",
    "# STUDENT INTERACTION 3\n",
    "print(\"\\nü§î STUDENT EXERCISE 3:\")\n",
    "print(\"Add your own texts to the list and see how they compare!\")\n",
    "print(\"Which pairs have the highest/lowest similarity? Does it make sense?\")\n",
    "\n",
    "# TODO: Students add their texts here\n",
    "student_texts = [\n",
    "    \"Your text 1 here\",\n",
    "    \"Your text 2 here\",\n",
    "    # Add more texts...\n",
    "]\n",
    "\n",
    "# Semantic search example\n",
    "def semantic_search(query, documents, top_k=3):\n",
    "    \"\"\"Find most similar documents to a query\"\"\"\n",
    "    query_embedding = sentence_model.encode([query])\n",
    "    doc_embeddings = sentence_model.encode(documents)\n",
    "    \n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'document': documents[idx],\n",
    "            'similarity': similarities[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Example semantic search\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with multiple layers.\",\n",
    "    \"Natural language processing helps computers understand text.\",\n",
    "    \"Computer vision enables machines to interpret visual information.\",\n",
    "    \"Reinforcement learning trains agents through trial and error.\"\n",
    "]\n",
    "\n",
    "query = \"How do computers understand language?\"\n",
    "search_results = semantic_search(query, documents)\n",
    "\n",
    "print(f\"\\nüîç Semantic Search Results for: '{query}'\")\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    print(f\"{i}. (Score: {result['similarity']:.3f}) {result['document']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: DYNAMIC FEW-SHOT PROMPTING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 3: DYNAMIC FEW-SHOT PROMPTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class DynamicFewShotPrompter:\n",
    "    def __init__(self, examples, sentence_model):\n",
    "        self.examples = examples\n",
    "        self.sentence_model = sentence_model\n",
    "        \n",
    "    def get_relevant_examples(self, query, k=3):\n",
    "        \"\"\"Retrieve k most similar examples to the query\"\"\"\n",
    "        query_embedding = self.sentence_model.encode([query])\n",
    "        example_texts = [ex['input'] for ex in self.examples]\n",
    "        example_embeddings = self.sentence_model.encode(example_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(query_embedding, example_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        \n",
    "        return [self.examples[idx] for idx in top_indices]\n",
    "    \n",
    "    def create_prompt(self, query, task_description, k=3):\n",
    "        \"\"\"Create a dynamic few-shot prompt\"\"\"\n",
    "        relevant_examples = self.get_relevant_examples(query, k)\n",
    "        \n",
    "        prompt = f\"{task_description}\\n\\n\"\n",
    "        \n",
    "        for ex in relevant_examples:\n",
    "            prompt += f\"Input: {ex['input']}\\nOutput: {ex['output']}\\n\\n\"\n",
    "        \n",
    "        prompt += f\"Input: {query}\\nOutput:\"\n",
    "        return prompt\n",
    "\n",
    "# Example dataset for sentiment analysis\n",
    "sentiment_examples = [\n",
    "    {\"input\": \"I love this movie!\", \"output\": \"positive\"},\n",
    "    {\"input\": \"This food tastes terrible\", \"output\": \"negative\"},\n",
    "    {\"input\": \"The weather is nice today\", \"output\": \"positive\"},\n",
    "    {\"input\": \"I'm feeling sad\", \"output\": \"negative\"},\n",
    "    {\"input\": \"This book is okay\", \"output\": \"neutral\"},\n",
    "    {\"input\": \"Amazing service at this restaurant\", \"output\": \"positive\"},\n",
    "    {\"input\": \"The product broke after one day\", \"output\": \"negative\"},\n",
    "    {\"input\": \"Not bad, could be better\", \"output\": \"neutral\"},\n",
    "    {\"input\": \"Absolutely fantastic experience\", \"output\": \"positive\"},\n",
    "    {\"input\": \"Waste of money\", \"output\": \"negative\"}\n",
    "]\n",
    "\n",
    "# Initialize dynamic prompter\n",
    "prompter = DynamicFewShotPrompter(sentiment_examples, sentence_model)\n",
    "\n",
    "# Test dynamic prompting\n",
    "test_query = \"This pizza is incredibly delicious\"\n",
    "dynamic_prompt = prompter.create_prompt(\n",
    "    test_query, \n",
    "    \"Classify the sentiment of the following text as positive, negative, or neutral:\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"üìù Dynamic Few-shot Prompt for: '{test_query}'\")\n",
    "print(f\"\\n{dynamic_prompt}\")\n",
    "\n",
    "# Compare with random few-shot\n",
    "random_examples = random.sample(sentiment_examples, 3)\n",
    "random_prompt = \"Classify the sentiment of the following text as positive, negative, or neutral:\\n\\n\"\n",
    "for ex in random_examples:\n",
    "    random_prompt += f\"Input: {ex['input']}\\nOutput: {ex['output']}\\n\\n\"\n",
    "random_prompt += f\"Input: {test_query}\\nOutput:\"\n",
    "\n",
    "print(f\"\\nüìù Random Few-shot Prompt (for comparison):\")\n",
    "print(f\"\\n{random_prompt}\")\n",
    "\n",
    "# STUDENT INTERACTION 4\n",
    "print(\"\\nü§î STUDENT EXERCISE 4:\")\n",
    "print(\"Try different queries and compare dynamic vs random few-shot selection.\")\n",
    "print(\"Do you notice any differences in the selected examples?\")\n",
    "\n",
    "# TODO: Students test with their own queries\n",
    "student_query = \"I'm not sure how I feel about this\"\n",
    "student_prompt = prompter.create_prompt(student_query, \"Classify sentiment:\", k=3)\n",
    "print(f\"\\nYour dynamic prompt preview:\\n{student_prompt[:200]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: TRAINING BERT ON SYNTHETIC LLM LABELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 4: TRAINING BERT ON SYNTHETIC LLM LABELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create synthetic dataset (simulating LLM-generated labels)\n",
    "synthetic_data = [\n",
    "    {\"text\": \"I absolutely love this product\", \"label\": 1},\n",
    "    {\"text\": \"This is terrible quality\", \"label\": 0},\n",
    "    {\"text\": \"Not sure about this purchase\", \"label\": 2},\n",
    "    {\"text\": \"Best decision ever\", \"label\": 1},\n",
    "    {\"text\": \"Completely disappointed\", \"label\": 0},\n",
    "    {\"text\": \"It's alright, nothing special\", \"label\": 2},\n",
    "    {\"text\": \"Highly recommend to everyone\", \"label\": 1},\n",
    "    {\"text\": \"Worst experience ever\", \"label\": 0},\n",
    "    {\"text\": \"Could be better or worse\", \"label\": 2},\n",
    "    {\"text\": \"Exceeded my expectations\", \"label\": 1}\n",
    "]\n",
    "\n",
    "# Convert to dataset format\n",
    "df = pd.DataFrame(synthetic_data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print(\"üìä Synthetic Dataset Overview:\")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n",
    "print(f\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Load BERT model for sequence classification\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=3  # positive, negative, neutral\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the input texts\"\"\"\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Split into train/test (small dataset, so simple split)\n",
    "train_size = int(0.8 * len(tokenized_dataset))\n",
    "train_dataset = tokenized_dataset.select(range(train_size))\n",
    "test_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n",
    "\n",
    "print(f\"\\nüìö Dataset Split:\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Define training arguments (simplified for workshop)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Metric computation function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nüèãÔ∏è Starting BERT Training...\")\n",
    "print(\"Note: This is a simplified example. In practice, you'd use larger datasets!\")\n",
    "\n",
    "# Train the model (commented out to avoid long execution time in demo)\n",
    "# trainer.train()\n",
    "\n",
    "print(\"‚úÖ Training setup complete!\")\n",
    "print(\"\\nIn a real scenario, you would:\")\n",
    "print(\"1. Generate more synthetic labels using an LLM\")\n",
    "print(\"2. Clean and validate the synthetic data\")\n",
    "print(\"3. Train on a larger dataset\")\n",
    "print(\"4. Evaluate on human-labeled test data\")\n",
    "print(\"5. Compare performance with the original LLM\")\n",
    "\n",
    "# STUDENT INTERACTION 5\n",
    "print(\"\\nü§î FINAL STUDENT EXERCISE:\")\n",
    "print(\"Discussion Questions:\")\n",
    "print(\"1. What are the advantages of training BERT on LLM-generated labels?\")\n",
    "print(\"2. What potential issues should we watch out for?\")\n",
    "print(\"3. How would you validate that the synthetic labels are good quality?\")\n",
    "print(\"4. In what scenarios would this approach be most useful?\")\n",
    "\n",
    "# Quick inference example (without training)\n",
    "def predict_sentiment(text):\n",
    "    \"\"\"Quick inference example\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "    \n",
    "    labels = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
    "    confidence = predictions[0][predicted_class].item()\n",
    "    \n",
    "    return labels[predicted_class], confidence\n",
    "\n",
    "# Test the model (before training, so results will be random)\n",
    "test_text = \"I think this workshop was helpful\"\n",
    "prediction, confidence = predict_sentiment(test_text)\n",
    "print(f\"\\nüîÆ Model Prediction (before fine-tuning):\")\n",
    "print(f\"Text: '{test_text}'\")\n",
    "print(f\"Prediction: {prediction} (confidence: {confidence:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ WORKSHOP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Key Takeaways:\")\n",
    "print(\"‚úÖ Zero-shot vs Few-shot prompting strategies\")\n",
    "print(\"‚úÖ Text similarity with transformer embeddings\")\n",
    "print(\"‚úÖ Dynamic example selection for better prompting\")\n",
    "print(\"‚úÖ Training smaller models on LLM-generated data\")\n",
    "print(\"\\nNext steps: Experiment with larger datasets and different model architectures!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
