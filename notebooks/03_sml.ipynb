{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolaiberk/llm_ws/blob/main/notebooks/03_sml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy1fVofLOAq4"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!pip install nltk\n",
        "!pip install eli5\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KVhbic470nv"
      },
      "source": [
        "# An Introduction to Supervised Learning with Scikit learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmoWfquYODzt"
      },
      "source": [
        "Classifications can take many forms. Today, we will train a simple binary sentiment classifier, using a subset of 10,000 [Amazon Reviews provided as part of a Kaggle competition](https://www.kaggle.com/datasets/bittlingmayer/amazonreviews?resource=download). We will use the amazing `scikit-learn` package to transform the data and train our classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCXdH4LiOs36"
      },
      "source": [
        "## A Minimal Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmx9Tbptb4I"
      },
      "source": [
        "We first load some basic packages and the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyx-mllorlZR"
      },
      "outputs": [],
      "source": [
        "# fundamental packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# load some data to train our classifier on\n",
        "reviews = pd.read_csv(\"https://www.dropbox.com/scl/fi/y1fzhtdkw8m3swkxb9gif/sub_sample.csv?rlkey=ssaut1n6dua1cihgwww9bxnrm&dl=1\")\n",
        "reviews[\"bin_label\"] = reviews.label == \"good\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXFZKxn7ziuB"
      },
      "outputs": [],
      "source": [
        "reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8N0qUySxsAe"
      },
      "outputs": [],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_bKnN_zOBq"
      },
      "source": [
        "The data has a simple structure, with 10,000 observations and two variables/columns, \"label\" and \"text\". The label is either \"good\"or \"bad\". We added a binary version of the label as a third variable. Our task is now to train a classifier that cann tell tehse two labels apart, based on the text of the review. For that, we need some tools!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSMvlWwqkdAL"
      },
      "source": [
        "### A Quick Intro to `scikit-learn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Z1bjMoiA1G"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "url = 'https://scikit-learn.org/stable/'\n",
        "iframe = '<iframe src=' + url + ' width=1600 height=350></iframe>'\n",
        "IPython.display.HTML(iframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQli_u4Mrizc"
      },
      "source": [
        "`scikit-learn` is an amazing package, catering to pretty much every need of data scientist. **In order to train a classifier, we need a model that we can train and a vectorizer to transform our data**, that's pretty much it. `scikit-learn` offers much more (please go check it out already!), like a function to transform our data in training and testing data and functions to bind them together and produce our metrics. **We load all of this below**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALUy1tqOk651"
      },
      "outputs": [],
      "source": [
        "# load relevant tools\n",
        "\n",
        "## A model (choose from API)\n",
        "from sklearn.linear_model import LogisticRegression as LogReg\n",
        "\n",
        "## A vectorizer to transform our text into numbers\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "## A function to split our data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## A pipeline to put it all together, and a few functions to compute how well our classifier performs\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SeFv29i1Qiz"
      },
      "source": [
        "Let's split our data into train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKTbFt-41Pjf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    reviews.text, reviews.bin_label, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoBhnCAo1ZaZ"
      },
      "source": [
        "Now we need literally two lines of code to train the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnR9ykwu1Y1M"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([('Tfidf', TfidfVectorizer()), ('LogReg', LogReg())])\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPJfOxx1g7e"
      },
      "source": [
        "![](https://media.giphy.com/media/zXMRfbsHOAire/giphy.gif)\n",
        "\n",
        "Don't believe me? Check for yourself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6raSEFyK56Nn"
      },
      "outputs": [],
      "source": [
        "pipe.predict([\"This is a great movie\",\n",
        "              \"Never hated something as much as this movie\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFBMZjISUc98"
      },
      "source": [
        "It does predict our examples well, but how good is the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOZzD9jeUhxO"
      },
      "outputs": [],
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "pd.crosstab(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNoZR8vjU6Nj"
      },
      "outputs": [],
      "source": [
        "## define a custom function to report metrics\n",
        "def accuracy_report(y_test, y_pred):\n",
        "  print(\"Accuracy: \",  round(accuracy_score(y_test, y_pred), 3))\n",
        "  print(\"Recall: \",    round(recall_score(y_test, y_pred), 3))\n",
        "  print(\"Precision: \", round(precision_score(y_test, y_pred), 3))\n",
        "  print(\"F1: \",        round(f1_score(y_test, y_pred), 3))\n",
        "\n",
        "accuracy_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDlTixZSWPxI"
      },
      "source": [
        "Pretty good, huh? Let's see how this works in more detail!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDlWwbv-k7Yw"
      },
      "source": [
        "## Under the Hood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnfmt7h_fYyG"
      },
      "source": [
        "Let's show this based on a very simple example. We generate a set of example texts that are positive or negative reviews and check what the classifier does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAMu9ilAfYgO"
      },
      "outputs": [],
      "source": [
        "example_revs = [\"This is a great, great movie\",\n",
        "                \"This is a horrible movie\",\n",
        "                \"Waste of time\",\n",
        "                \"Beautiful\"]\n",
        "\n",
        "example_y = [True, False, False, True]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsnEMd83-70P"
      },
      "source": [
        "### Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcqIremTkvAv"
      },
      "source": [
        "We choose a vectorizer for our text [from `scikit-learn`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) and assign it to an object so we can fit it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmkdS8WtkuPt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec  = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1XtT1nlSZq"
      },
      "source": [
        "Then, we fit it to our example reviews and transform the text into numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpBCdkEKfVfw"
      },
      "outputs": [],
      "source": [
        "sparse_mtrx = vec.fit_transform(example_revs)\n",
        "print(vec.get_feature_names_out(), \"\\n\", sparse_mtrx.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJmaZUMS9r9I"
      },
      "source": [
        "We can see that the vectorizer simply counts the occurence of each word in each text. The vectorizer by default strips all accents and converts all words into lowercase. Now we can use the `transform()` function to transform new texts into the same format. This is particularly important when we need to transform texts in the test set into a matrix based on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-boZz6uA729"
      },
      "outputs": [],
      "source": [
        "vec.transform([\"This movie is not good.\"]).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Yaj6vwBNkL"
      },
      "source": [
        "We can see that some features ('not' and 'good') from this new text are not encoded, as the vectorizer does not have an appropriate column in the document-term-matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8evd5J46AXk5"
      },
      "source": [
        "Vectorizers have many more features that can be used to preprocess the text. Below is an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd-T9_C5-3_3"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer(stop_words=[\"this\", \"is\", \"of\"])\n",
        "sparse_mtrx = vec.fit_transform(example_revs)\n",
        "\n",
        "## use the command from above to rpint your transformed matrix\n",
        "print(vec.get_feature_names_out(), \"\\n\", sparse_mtrx.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO47B3KIOArK"
      },
      "source": [
        "Look up the arguments of the [`CountVectorizer()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) and test it yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYzSPEmkOArK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ikxcQYF_yMR"
      },
      "source": [
        "### Fitting the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bJOV4iNARRL"
      },
      "source": [
        "Now that we know how to convert text into numbers, we can fit a classifier to the data in order to predict observations in the test set (we use our initial data again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlJhj4_n_8Zz"
      },
      "outputs": [],
      "source": [
        "## train-test-split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  reviews.text, reviews.bin_label, test_size=0.33, random_state=42)\n",
        "\n",
        "## vectorize data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(ngram_range=(1,2))\n",
        "\n",
        "X_train = vec.fit_transform(X_train)\n",
        "\n",
        "## load a classifier of your choosing\n",
        "from sklearn.linear_model import SGDClassifier as SVM\n",
        "clsfr = SVM()\n",
        "\n",
        "## fit\n",
        "clsfr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x1_QmlwRd00"
      },
      "source": [
        "Now we can assess performance same as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCUBhveLRcb8"
      },
      "outputs": [],
      "source": [
        "X_test  = vec.transform(X_test)\n",
        "y_pred = clsfr.predict(X_test)\n",
        "\n",
        "pd.crosstab(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9XTTP1yRoeo"
      },
      "outputs": [],
      "source": [
        "accuracy_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0nLXD2MlRT6"
      },
      "source": [
        "## Improving your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtVbJUoKTmuh"
      },
      "source": [
        "### Preprocessing with [`spaCy`](https://spacy.io/)\n",
        "\n",
        "Sometimes, you might want to pre-select features based on your classification problem. For example, when you are interested in the topic of a text, it might be sufficient to assess the nouns which are used, whereas other words might introduce mostly noise. Other tasks might require you to identify the object in a sentence or the organisation mentioned in a text. `spaCy` can identify these words through **parts-of-speech tagging**, **Dependency Parsing**, and **named entity recognition**. However, `spaCy` can do much more. Their [website](https://course.spacy.io/en/) provides an entire course from finding words to training a neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NL9W7c9OArM"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH91FNjMiVXz"
      },
      "source": [
        "#### Parts-of-speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUfFxHG4VM9G"
      },
      "outputs": [],
      "source": [
        "# Process a text\n",
        "doc = nlp(\"Not the hero we deserve, but the hero we need.\")\n",
        "\n",
        "# Iterate over the tokens\n",
        "for token in doc:\n",
        "    # Print the text and the predicted part-of-speech tag\n",
        "    print(token.text, token.pos_)\n",
        "\n",
        "# what's PRON? get an explanation:\n",
        "spacy.explain(\"PRON\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnm7Acftcc35"
      },
      "outputs": [],
      "source": [
        "# retain only the nouns of a set of texts:\n",
        "docs = [\"May the force be with you.\",\n",
        "        \"You're gonna need a bigger boat!\",\n",
        "        \"Fly, you fools!\",\n",
        "        \"And I will strike down upon thee with great vengeance and furious anger!\",\n",
        "        \"You can't handle the truth!\",\n",
        "        \"You take the blue pill, the story ends; you wake up in your bed and believe whatever you want to believe.\",\n",
        "        \"I love the smell of napalm in the morning.\"]\n",
        "\n",
        "\n",
        "for doc in nlp.pipe(docs):\n",
        "  print([token.text for token in doc if token.pos_ == 'NOUN'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-b3kdUn9NAv"
      },
      "source": [
        "Another package commonly used in text analysis is [`nltk`](https://www.nltk.org/). It has similar functionalities as `spacy` (e.g. parts-of-speech-tagging) but a slightly different implementation. Below, it is shown how to remove stopwords and stem with `nltk`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spp0rtypigha"
      },
      "source": [
        "#### Stopword removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4OASjJgBvn1"
      },
      "source": [
        "Many words that are constantly used in everyday language are usually not very informative about the content of text (see [Pennebaker 2011](http://secretlifeofpronouns.com/) for a contrasting perspective). These words are called 'stopwords' in NLP and usually considered clutter that could and should be removed.\n",
        "\n",
        "Note however that preprocessing can heavily affect model results ([Denny and Spirling 2018](https://www.cambridge.org/core/journals/political-analysis/article/text-preprocessing-for-unsupervised-learning-why-it-matters-when-it-misleads-and-what-to-do-about-it/AA7D4DE0AA6AB208502515AE3EC6989E)). How to preprocess text in general is a decision that should be made based on careful consideration of the problem at hand ([Grimmer and Stewart 2013](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F7AAC8B2909441603FEB25C156448F20/S1047198700013401a.pdf))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGn0m_hJiqAI"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccJ53_LZ-jbh"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_docs = []\n",
        "\n",
        "for doc in docs:\n",
        "  filtered_doc = \" \".join([w for w in word_tokenize(doc) if not w.lower() in stop_words])\n",
        "  filtered_docs.append(filtered_doc)\n",
        "\n",
        "filtered_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5z31OiwicQZ"
      },
      "source": [
        "#### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6NyTTTnigJp"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "stemmed_docs = []\n",
        "\n",
        "for doc in docs:\n",
        "  stemmed_doc = \" \".join([stemmer.stem(w) for w in word_tokenize(doc)])\n",
        "  stemmed_docs.append(stemmed_doc)\n",
        "\n",
        "stemmed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_Xrdn8PCqR"
      },
      "source": [
        "### Optimizing Model Fit and Avoiding Overfit with CrossValidation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eOKnsmJcINb"
      },
      "source": [
        "**Overfitting** describes the problem that we might have a classifier fitting our data a little too well, in that it **does not describe general patterns** anymore, but potentially incorporate some **idiosyncratic noise** in the training data. The visualisation below from the [`scikit-learn` guide on overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html?highlight=crossvalidation#underfitting-vs-overfitting) tries to describe this problem.\n",
        "\n",
        "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_underfitting_overfitting_001.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3rrA3v9btQA"
      },
      "source": [
        "Often, we might want to test models with different parameters and choose the one that fits best to solve our problem. This will generally increase the fit of our data but also potentially lead to overfitting. A particularly good way to deal with this is called **cross-validation**. In this process, the training data is divided into equally sized subsets and then, several classifiers are trained to predict each subset from the other subsets. This way, the influence of single observations is reduced, because each observation is in the test set once. More on this [here](https://scikit-learn.org/stable/modules/cross_validation.html) and [here](https://cssbook.net/chapter08.html#8_5_3).\n",
        "\n",
        "`scikit-learn` contains many models like `LogisticRegressionCV()`, which implement this by default. However, using `GridSearchCV()`, we can optimise the parameters of any model. In order to optimise the parameters of our model, we first need to check which parameters *can* be tuned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyMI5UGMZjQA"
      },
      "outputs": [],
      "source": [
        "?LogReg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YXn33ytqYsA"
      },
      "source": [
        "In `LogisticRegression()`, we can change the regularization technique with `penalty` (regularisation is a [process](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c) decreasing the importance of unimportant features, which avoids overfitting when classifying with many features). We can also change the degree of regularization using `C`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hli4P-0Wrmm7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [\n",
        "    {\"penalty\": [\"l1\", \"l2\"], \"C\": [1, 10, 100, 1000]}\n",
        "]\n",
        "\n",
        "score = \"f1\"\n",
        "\n",
        "clf = GridSearchCV(LogReg(solver = 'liblinear'), tuned_parameters, scoring=\"%s_macro\" % score)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op8Cd0gUr5kf"
      },
      "source": [
        "Let's see if a classifier with these parameters outperforms the standard model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtvGLq2ntKDp"
      },
      "outputs": [],
      "source": [
        "clsfr_std = LogReg(solver = 'liblinear')\n",
        "clsfr_new = LogReg(solver = 'liblinear', C = 1000, penalty = \"l2\")\n",
        "\n",
        "clsfr_std.fit(X_train, y_train)\n",
        "clsfr_new.fit(X_train, y_train)\n",
        "\n",
        "y_pred_std = clsfr_std.predict(X_test)\n",
        "y_pred_new = clsfr_new.predict(X_test)\n",
        "\n",
        "accuracy_report(y_test, y_pred_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYeA1fwZtyYY"
      },
      "outputs": [],
      "source": [
        "accuracy_report(y_test, y_pred_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3M7vdfKt8hr"
      },
      "source": [
        "We managed to improve our classifier!\n",
        "\n",
        "![](https://media.giphy.com/media/a0h7sAqON67nO/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKBWEKavPHn9"
      },
      "source": [
        "### BONUS: Feature Assessment with [`eli5`](https://eli5.readthedocs.io/en/latest/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDP6Q1o2u19M"
      },
      "source": [
        "`eli5` is a great package to understand how our classifier makes decisions. It has two main functions: `show_weights()` tells us which features are most predictive for the classification, and `show_prediction()` explains us how each feature affects the prediction for a single example. This can be particularly useful for iterative feature selection and the exclusion of stopwords, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA0ugrF1Zeaw"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "eli5.show_weights(clsfr, vec=vec, feature_names=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXZQeOJHvmOV"
      },
      "outputs": [],
      "source": [
        "eli5.show_prediction(clsfr, reviews.text[400], vec=vec, feature_names=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqZ1918DOArR"
      },
      "source": [
        "# Now, it's your turn!\n",
        "\n",
        "Together with your neighbor, you have 15 minutes to **design an algorithm that can detect happiness online**. The training data contains tweets with different emotions, your challenge is to find the happy ones. Apply what you have learned in the past hour (feel free to copy the code from the other script). The last two cells contain code to load the test data and assess your classifier's performance. The link to the training set will be sent to you after the fifteen minutes have passed.\n",
        "\n",
        "## **The best F1 score wins!!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJX2dG1kOArR"
      },
      "outputs": [],
      "source": [
        "tweets = pd.read_csv(\"https://www.dropbox.com/scl/fi/q4knjtpx0cw15v55q61vr/train_balanced.csv?rlkey=87djtsvsfx5mb1rgvpy0jsjz8&dl=1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZov60hlOArR"
      },
      "source": [
        "# Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF1EIRlvOArY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "def performance_report(y_test, y_pred):\n",
        "  print(\"Accuracy: \",  round(accuracy_score(y_test, y_pred), 3))\n",
        "  print(\"Recall: \",    round(recall_score(y_test, y_pred), 3))\n",
        "  print(\"Precision: \", round(precision_score(y_test, y_pred), 3))\n",
        "  print(\"F1: \",        round(f1_score(y_test, y_pred), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WKYtO15OArY"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"\")\n",
        "X_test = vec.transform(test.content)\n",
        "y_test = test.happiness\n",
        "performance_report(y_test, classifier.predict(X_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Kopie von Kopie von IntroMLSklearn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}