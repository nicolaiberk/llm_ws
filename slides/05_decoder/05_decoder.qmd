---
title: "Generative LLMs"
author: "Nicolai Berk"
subtitle: "Crash-course LLMs for Social Science"
date: "2025-09-12"
description: "This session covers generative decoder models."
keywords: ["gpt", "decoder", "large language models", "machine learning", "nlp"]
format:
    revealjs:
        theme: simple
        slide-number: true
        toc: false
bibliography: "../references.bib"
---


## Recap: Encoder Models (BERT)

<br>

- Input: "The [MASK] is barking loudly"
- BERT: Processes entire sentence simultaneously
- Output: probability distribution across tokens ("dog" (87%), "puppy" (8%), "animal" (3%))
- Bidirectional: Reads text in both directions

### Masked Language Modeling: Trained to fill in blanks

## Recap: Downstream Encoder Tasks

<br>

- Classify documents
- Extract information
- Measure similarity


## How a Decoder Works {auto-animate="true"}

<br>

![Source: @tunstall2022natural](vis/decoder.png)

## How a Decoder Works {auto-animate="true"}

![Source: @tunstall2022natural](vis/decoder.png)

- Input: "Cause and..."
- **Predicts next token**: "effect"
- Repeats until stopping condition
- *Autoregressive* generation

#### "Causal" language modeling


## Major differences

<br>

::: columns
::: column

- **Autoregressive**: Generates one word at a time
- **"Causal" attention**: Only looks at previous words
- **Massive scale**: Often billions of parameters

:::
::: column

![](vis/gpt.png)

:::
:::


## What does this look like?

### [Visualization](https://bbycroft.net/llm)

<br>

Take 5-10 minutes to explore the visualization and discuss with your neighbor how the decoder architecture works.


## Training GPT

<br>

- Pretraining: predict the next word (causal LM objective)
- Scale = data + parameters + compute
- Fine-tuning:
  - Instruction tuning (datasets of Q&A)
  - RLHF^[Reinforcement Learning with Human Feedback] (aligning with human preferences)

## Decoder Tasks

- Content generation

. . .

### Surprisingly generalizable task!

- Zero/few-shot Classification
- Code generation
- Translation
- App development

...many more things it was not trained to do!

## Social Science applications

- Annotation
- Extraction/text-mining
- Generating experimental treatments
- Adaptive surveys
- Literature reviews
- Simulation of social behaviour?
- Policy simulation?

# Inference with LLMs

## Prompting

![](vis/meme.jpg)

#### Remember: prompt engineering on the *validation* set!

## Writing a good prompt

- <mark>Persona</mark>
- **Task**
- Context
- *Format*

<mark>You are a program manager in [industry].</mark> **Draft an executive summary email** to [persona] based on [details
about relevant program docs]. *Limit to bullet points.*

::: aside
[Google prompting guide](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf)
:::

## Controlling model output 

### [`pydantic`](https://docs.pydantic.dev/latest/concepts/models/#validating-data)

Let's you impose structure on model outputs.

```{python}
#| eval: false
#| echo: true

class CityLocation(BaseModel):
    city: str
    country: str


agent = Agent('google-gla:gemini-1.5-flash', output_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.output)
#> city='London' country='United Kingdom'
```



::: aside
::: fragment

#### See also

- [Ollama structured output](https://ollama.com/blog/structured-outputs)
- [OpenAI function calls](https://platform.openai.com/docs/guides/function-calling#defining-functions)

:::
:::

## Labelling with LLMs

<br>

- **Zero-shot**: just prompt provided
- **Few-shot**: a few examples provided
- **Dynamic few-shot**: examples selected based on similarity to the input

## Few-shot labelling example

<br>

```
Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:
positive, negative, or neutral.

Examples:
Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.
Label: positive
Text: The company generated net sales of 11.3 million euro this year.
Label: neutral
Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.	
Label: negative
```

## Dynamic few-shot labelling

<br>

#### Idea: most similar examples should be most informative

1. Use cosine_similarity of embedding to assess similarity
2. Add k most similar examples to the prompt

## Retrieval Augmented Generation (RAG)

<br>

1. Retrieve most likely examples given a query (e.g. context for question)
2. [Optional: rerank generated examples using cross-encoder]
3. Use these examples in the prompt to generate an answer

Use-cases: archival research, chatbots, ...

## Synthetic Annotation

![Source: [Moritz Laurer on HF Blog](https://huggingface.co/blog/synthetic-data-save-costs#conclusion)](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/176_synthetic-data-save-costs/table_pros_cons.png)

## Synthetic Annotation

<br>

- Use LLM to annotate training data
- Generate synthetic labels
- Train smaller encoder model on synthetic data
- Evaluate on gold standard
- Apply cost-efficient at scale

## Zero-shot encoder models 

### @laurer2024less

- Task: natural-language inference (NLI) - universal
- Allow prompting
- Controlled output
- Class probabilities
- Efficient

::: fragment

#### Try this before using generative models

:::

## How does it work?

<br>

![@laurer2024less, Table 1](vis/nli.png)

## How does it work?

<br>

-  Class-hypotheses: “It is about economy", "it is about democracy", ...
-  E.g. “We need to raise tariffs” as context
-  Test each of the class-hypotheses against this context
-  Probabilities for entailment and contradiction are converted to label probabilities

::: aside
[More](https://huggingface.co/tasks/zero-shot-classification)
:::

# Tutorial I

LLM inference and prompting

[Notebook](https://colab.research.google.com/github/nicolaiberk/llm_ws/blob/main/notebooks/05a_prompting.ipynb)


# Hosting Models & Calling APIs

## [HF Inference Endpoints](https://endpoints.huggingface.co/)

![](vis/hf_inf.png)

## Local Hosting

### Ollama

<br>

```{python}
#| eval: false
#| echo: true

from ollama import chat
from ollama import ChatResponse

response: ChatResponse = chat(model='gemma3', messages=[
  {
    'role': 'user',
    'content': 'Why is the sky blue?',
  },
])
print(response['message']['content'])
# or access fields directly from the response object
print(response.message.content)
```

## [Azure](https://oai.azure.com)

![](vis/oai.png)

## OpenAI

<br>

```{python}
#| eval: false
#| echo: true

from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="Write a short bedtime story about a unicorn."
)

print(response.output_text)
```

# Tutorial II

API calls, Structured Output

[Notebook](https://colab.research.google.com/github/nicolaiberk/llm_ws/blob/main/notebooks/05b_api.ipynb)



## Resources
