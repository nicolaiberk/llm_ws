---
title: "Lecture 2: BERT"
author: "Nicolai Berk"
subtitle: "CUSO WS on Large Language Models"
date: "2025-09-03"
description: "This lecture covers the concept of embeddings in the context of large language models."
keywords: ["bert", "large language models", "machine learning", "nlp"]
format:
    revealjs:
        theme: simple
        slide-number: true
        toc: false
bibliography: "../references.bib"
---

## Today

::: incremental

- Advanced Tokenization
- Contextualized Embeddings
- The Transformer Architecture
- The Huggingface Ecosystem
- Fine-tuning a Transformer Model
- Validation & Evaluation

:::

# Tokenization

## Issues with simple word tokenization

<br>

### Consider the following words:

"national", "nationalism", "nationalist", "nationalize"

#### What are potential issues with simple word tokenization here?


::: fragment

<br>

### Any ideas how to solve these issues?

:::

## Solution: Subword Tokenization

<br>

[vis]

## Solution: Subword Tokenization

<br>

- More efficient
  - Fewer tokens required for similar words
  - Generalization across similar words
- Able to assess out-of-vocabulary words

## How does it work?

## Special Tokens

<br>

- `[CLS]` token: Represents the entire input sequence
- `[SEP]` token: Separates different segments of text
- `[PAD]` token: Used for padding sequences to the same length
- `[UNK]` token: Represents unknown or out-of-vocabulary words
- `[MASK]` token: Used for masked language modeling tasks


# Contextualized Embeddings

The following slides are based @tunstall2022natural, Ch.2.

## Issues with Classic Embeddings

```{r}
#| fig.width: 5
#| fig.height: 3

library(ggplot2)
library(dplyr)

data.frame(
  word = c("flies", "glides", "soars", "insects", "bugs"),
  x = c(0.5, 0.1, 0.2, 0.8, 0.9),
  y = c(0.6, 0.25, 0.3, 0.9, 0.8),
  col = c("blue", "green", "green", "red", "red")
) %>% 
  ggplot(aes(x, y, label = word, color = col)) +
  geom_text() +
  xlim(0, 1) + ylim(0, 1) +
  theme_void() +
  theme(legend.position = "none")

```

## Issues with Classic Embeddings

### Contextual Meaning

<br>

### Sentence a: Time *flies* like an arrow

vs.

### Sentence b: Fruit *flies* like a banana

::: fragment

<br>

### How could we represent the different meanings?

:::

## Contextualized Embeddings

```{r}
#| fig.width: 5
#| fig.height: 3

library(ggplot2)
library(dplyr)

data.frame(
  word = c("flies (a)", "flies (b)", "glides", "soars", "insects", "bugs"),
  x = c(0.3, 0.75, 0.1, 0.2, 0.8, 0.9),
  y = c(0.35, 0.75, 0.25, 0.3, 0.9, 0.8),
  col = c("lightgreen", "lightred", "green", "green", "red", "red")
) %>% 
  ggplot(aes(x, y, label = word, color = col)) +
  geom_text() +
  xlim(0, 1) + ylim(0, 1) +
  theme_void() +
  theme(legend.position = "none")

```

## Contextualized Embeddings

### Contextual Meaning

<br>

### Sentence a: Time *flies* like an arrow

vs.

### Sentence b: Fruit *flies* like a banana

::: fragment

<br>

### How do you infer the different meanings?

:::

## Attention Mechanism: Intuition

![Source: @tunstall2022natural, Ch. 2](vis/attention_simple.png)

## Solution: Weighted Average

$$x'_i = \sum_{j=1}^{n} w_{ij} x_j$$

> **Weighted average** of all input embeddings

- $x'_i$: Contextualized embedding of token $i$
- $x_j$: Embedding of token $j$
- $w_{ij}$: Attention weight for token $j$ with respect to token $i$
- $n$: Number of tokens in the input sequence


## Step 1: Create query, key, and value vectors

<br>

- **Query**: Represents the token itself
- **Key**: Represents the context of the token
- **Value**: Again the token itself (more later)

## Step 2: Calculate the attention scores

<br>

> The dot product of the query and key vectors gives us the attention scores/weights

<br>

::: {.callout-important .fragment}

### What does the dot product of two vectors indicate?

:::


## Finalize: Normalize & take average

### Step 3: Normalize the attention scores

> The attention scores are normalized using the "softmax" function to ensure they sum to 1

::: fragment

### Step 4: Multiply the normalized scores with the value vectors and sum them up

$$x'_i = \sum_{j=1}^{n} w_{ij} x_j$$

:::

## Attention Mechanism: Example

![](vis/attention_contextual.png)

## Attention in Practice

<br>

- Query, key, and value vectors are **learned** representations
- Attention calculated for each hidden layer 
- Multiple attention 'heads' are used in parallel
- Outputs combined using another learned linear transformation

## Positional Encodings

<br>

- We can also capture the **position** of each token in the sequence
- Similar approach:
  - Create a vector for each position in the sequence
  - Add these vectors to the token embeddings
  - This allows the model to understand the order of tokens

# Tutorial I: Tokenization, Attention & Inference

# The Transformer Architecture

## Some terminology

::: callout-note

### Encoder (e.g. BERT)

:::: columns
::: column

- Converts an input sequence of tokens into a sequence of embedding vectors
- Tasks: Text classification, named entity recognition, extractive question answering, etc.

:::
::: column

![](vis/encoder.png)

:::
::::
:::

::: fragment
::: callout-important

### Decoder (e.g. GPT) - TOMORROW!

:::: columns
::: column

- Uses a sequence of embedding vectors to iteratively generate an output sequence of tokens, one token at a time
- Tasks: Mainly text generation, Chatbot responses, ...

:::
::: column

![](vis/decoder.png)

:::
::::
:::
:::



## Encoder Architecture

![Source: @devlin2019bert](vis/bert.png)

## Decoder Architecture

![Source: @devlin2019bert](vis/gpt.png)


## Transformers Overview

![](vis/transformers.png)


## The Encoder Architecture (e.g. BERT)

![Source: @tunstall2022natural, Ch. 2](vis/encoder_full.png)


# The Huggingface Ecosystem

## The Model Hub

## Tasks

## Model Selection

# Tutorial I: Tokenization & Inference

# Training a Transformer

## Transfer Learning

[Fig 1-7 NLP with Transformers]

## Training vs. Fine-Tuning

# Practical Considerations

# Tutorial II: Fine-tuning a Transformer

